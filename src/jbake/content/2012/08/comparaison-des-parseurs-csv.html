title=Comparaison des parseurs CSV
date=2012-08-23
type=post
tags=Comparatif,CSV,CsvEngine,Java
status=published
id=comparaison-des-parseurs-csv
~~~~~~
Mon petit projet "CsvEgine" commençant à ressembler à quelque chose, je vais me lancer dans un petit comparatifs des parseurs que je peux trouver sur internet.<br /><br />Pour pouvoir comparer ces différents parseurs je vais utiliser l'exemple basique de l'utilisation de CsvEngine : <a href="https://github.com/ybonnel/CsvEngine/wiki/Basics">Basics</a>.<br/>Il s'agit donc de parser un fichier CSV contenant des chiens avec comme attributs le nom, la race et le propriétaire.<br/>On verra également comment écrire le fichier. <br/>La troisième étape de comparaison sera la validation : <ul><li>Le nom et la race sont obligatoires</li><li>La race doit faire partie d'une liste connues de races</li></ul><br/>La quatrième étape sera du parsing CSV complexe, ajout de retour à la ligne pour le propriétaire. <br/><br/>Et enfin pour finir la comparaison je finirai avec un petit bench, en reprenant ce que j'avais fait mon "CsvEngine" (qui à l'époque s'appelait MoteurCsv) : <a href="http://www.ybonnel.fr/2012/02/bench-de-moteurcsv.html">Bench MoteurCsv</a><br/><br/>Pour la liste des parseurs, je suis parti de cet article : <a href="http://www.improve-technologies.com/2012/07/18/java-et-csv-tour-dhorizon-des-solutions-open-source/">Java et CSV tour d'horizon des solutions open-source</a><br/>Je rajouterai quand même CsvEngine :) <br/><br/>Comme d'habitude, l'ensemble du code est disponible sur github : <a href="https://github.com/ybonnel/CsvJavaComparaison">CsvJavaComparaison</a>. <br/><br/> <h1>BeanFiles</h1> Site : <a href="http://code.google.com/p/beanfiles/">http://code.google.com/p/beanfiles/</a><br/><br/> <h2>Étape 0 : Documentation et mise en place</h2>Voici tout d'abord les problèmes que j'ai rencontré avec BeanFiles pour la mise en place : <ul><li>La documentation est très pauvre : une page sur le wiki, plus une classe de test.</li><li>BeanFiles est une librairie construite avec maven, mais je n'ai pas trouvé de repo maven associé, ce qui a compliqué la mise en place</li><li>La documentation est relativement pauvre, elle ne contient qu'un exemple de code, mais pas de tuto de mise en place, du coup j'ai été obligé d'aller voir dans le pom.xml du code source pour avoir les dépendances.</li></ul> <br/><br/> <h2>Étape 1 : Lecture du fichier CSV simple</h2>La mise en place est relativement simple une fois que les problèmes ont été résolus :). <br/>Mise à part les problèmes sités plus haut, BeanFiles n'aime pas du tout avoir des lignes vides à la fin du fichier.<br/>Une autre limitation, les attributs de la classe doivent avoir les mêmes noms que les entêtes dans le fichier CSV.  <br/><br/> La lecture est relativement simple : <pre class="brush: java">public List&lt;Dog&gt; getDogs(InputStream stream) throws IOException {<br />    CSVReaderIterator&lt;Dog&gt; readerIterator = new CSVReaderIterator&lt;Dog&gt;(Dog.class, stream);<br />    stream.close();<br />    List&lt;Dog&gt; dogs = new ArrayList&lt;Dog&gt;();<br />    for (Dog dog : readerIterator) {<br />        dogs.add(dog);<br />    }<br />    return dogs;<br />}</pre>J'aurais préféré que la fermeture du stream soit gérée par la librairie.<br/>L'utilisation d'un iterator est pas bête, toutefois elle peux donner l'impression que la lecture du fichier se fait au fur et à mesure, alors que pas du tout :)<br/>Du coup comme la lecture est finie après l'appel au constructeur, j'aurais bien aimé pouvoir récupérer directement la liste (un getAll() sur l'iterator).<br/>Je trouve qu'avoir mis le parsing dans le constructeur n'est pas génial...<br/><br/> <h2>Étape 2 : écriture de fichier CSV</h2>Il n'est pas possible d'écrire avec cette librairie.<br/><br/> <h2>Étape 3 : validation</h2>Pas de validation non plus.<br/><br/> <h2>Étape 4 : parsing complexe.</h2>Aucun problème avec les retour à la ligne pour BeanFiles.<br/><br/> <h2>Étape 5 : bench</h2>Pour le bench, j'ai généré un fichier "moyen" (100 000 lignes) et un gros fichier (1 000 000 lignes).<br/>Pour le fichier moyen, le temps moyen de traitement est de 1292ms.<br/><br/> Pour le gros fichier, il a fallu que je monte la JVM à 2Go. C'est un problème que je vois à BeanFiles, il n'y a pas de possibilité d'ajouter un handler pour effectuer un traitement au fur et à mesure de la lecture. Pour traiter de gros fichiers, c'est donc un gros problème.<br/>Pour traiter ce fichier, le temps moyen de traitement est de 15120ms avec une consommation mémoire d'un peu moins de 1,6Go.<br/><br/> <h1>BeanIO</h1>BeanIO est sûrement très bien, mais j'aime pas trop les configuration XML, donc je passe.<br/><br/>  <h1>Commons-Csv</h1>Je ne l'ai pas étudié non plus, pour deux raisons : <ul><li>La version actuelle est la version 1.0-SNAPSHOT</li><li>C'est bas niveau, un peu comme open-csv</li></ul><br/><br/> <h1>CsvToSql</h1>Encore du XML... et en plus, ça n'a pas l'air adapté à ce que je veux faire.<br/><br/> <h1>FlatPack</h1>Encore du XML...<br/><br/> <h1>JavaCSV</h1>Les exemples de code montre que cette librairie ne fait pas vraiment du mapping : <a href="http://www.csvreader.com/java_csv_samples.php">JavaCSV Samples</a><br/><br/> <h1>JCsv</h1> Site : <a href="http://code.google.com/p/jcsv/">http://code.google.com/p/jcsv/</a><br/><br/> <h2>Étape 0 : Documentation et mise en place</h2>La mise en place est très simple et documentée, juste la dépendance à ajouter et c'est parti.<br/>C'est le gros point positif pour cette librairie la documentation est très riche.<br/><br/> <h2>Étape 1 : Lecture du fichier CSV simple</h2>Étant fan du principe des annotations, je choisi d'utiliser cette méthode pour mon parsing : <pre class="brush: java">public class Dog {<br />    @MapToColumn( column = 0)<br />    private String name;<br />    @MapToColumn( column = 1)<br />    private String race;<br />    @MapToColumn( column = 2)<br />    private String proprietary;<br />}</pre>J'aurais préféré pouvoir utiliser la ligne d'entête mais bon... <br/><br/>La lecture n'est pas très compliquée non plus : <pre class="brush: java">public List&lt;Dog&gt; getDogs(InputStream stream) throws IOException {<br />    Reader reader = new InputStreamReader(stream);<br /><br />    ValueProcessorProvider provider = new ValueProcessorProvider();<br />    CSVEntryParser&lt;Dog&gt; entryParser = new AnnotationEntryParser&lt;Dog&gt;(Dog.class, provider);<br />    CSVReader&lt;Dog&gt; csvDogReader = new CSVReaderBuilder&lt;Dog&gt;(reader)<br />            .entryParser(entryParser)<br />            .strategy(new CSVStrategy(',', '"', '#', true, true)).build();<br /><br />    return csvDogReader.readAll();<br />}</pre>Lors de mon premier essai, je n'avais pas mis de "strategy", et l'exception remontée n'était pas très parlante (ArrayIndexOutBoundException)... Mis à part ça, je n'ai pas eu de d'autres problèmes.<br/><br/> <h2>Étape 2 : écriture de fichier CSV</h2>L'écriture n'est pas très compliquée, par contre on ne peut pas utiliser les annotations, ce qui est un peu dommage. <pre class="brush: java">public void writeFile(List&lt;Dog&gt; dogs, File file) throws IOException {<br /><br />    CSVEntryConverter&lt;Dog&gt; entryConverter = new CSVEntryConverter&lt;Dog&gt;() {<br />        @Override<br />        public String[] convertEntry(Dog dog) {<br />            String[] columns = new String[3];<br />            columns[0] = dog.getName();<br />            columns[1] = dog.getRace();<br />            columns[2] = dog.getProprietary();<br /><br />            return columns;<br />        }<br />    };<br />    CSVWriter&lt;Dog&gt; csvDogWriter = new CSVWriterBuilder&lt;Dog&gt;(new FileWriter(file))<br />            .entryConverter(entryConverter)<br />            .strategy(new CSVStrategy(',', '"', '#', true, true))<br />            .build();<br />    csvDogWriter.writeAll(dogs);<br />    csvDogWriter.close();<br />}<br /></pre> Le résultat n'est pas très bon, si les champs contiennent des retours à la ligne, il n'ajoute pas les caractères '"' avant et après. Il n'ajoute pas l'entête.<br/>Bref, l'écriture existe, mais elle n'est pas satisfaisante de mon point de vue.<br/><br/> <h2>Étape 3 : validation</h2>Pas de principe de validation.<br/><br/> <h2>Étape 4 : parsing complexe.</h2>Aucun problème avec les retours à la ligne pour JCsv.<br/><br/> <h2>Étape 5 : bench</h2>J'utilise les mêmes fichiers que pour BeanFiles.<br/>Pour le fichier moyen, le temps moyen de traitement est de 39 219ms.<br/><br/>Pas de problème de consommation mémoire, JCsv permet de lire ligne par ligne, on a donc pas besoin de tout stocker dans une liste. Par contre les performances sont très mauvaises, cela provient du fait que JCsv appelle getAnnotations pour chaque ligne, et ne met rien en cache. <br/><br/>Le gros fichier confirme le bench avec le fichier moyen : <ul><li>Temps de traitement moyen : 367 449ms</li></ul><br/><br/> <h1>JSefa</h1> Site : <a href="http://jsefa.sourceforge.net/">http://jsefa.sourceforge.net/</a><br/><br/> <h2>Étape 0 : Documentation et mise en place</h2>La mise en place n'est pas documentée et il n'existe pas de repo maven (en tout cas je l'ai pas trouvé), par contre il suffit d'ajouter le jar.<br/>Au niveau documentation, il existe une page avec les exemples basiques, pour des trucs plus complexes, il faut regarder la javadoc ou le code source.<br/><br/> <h2>Étape 1 : Lecture du fichier CSV simple</h2>La déclaration du mapping via les annotations est plutôt simple : <pre class="brush: java">@CsvDataType<br />public class Dog {<br />    @CsvField(pos = 0)<br />    private String name;<br />    @CsvField(pos = 1)<br />    private String race;<br />    @CsvField(pos = 2)<br />    private String proprietary;<br />}</pre>J'aurais préféré pouvoir utiliser la ligne d'entête mais bon...<br/><br/>La lecture n'est pas très compliquée non plus : <pre class="brush: java">public List&lt;Dog&gt; getDogs(InputStream stream) throws IOException {<br />    CsvConfiguration config = new CsvConfiguration();<br />    config.setFieldDelimiter(',');<br />    Deserializer deserializer = CsvIOFactory.createFactory(config, Dog.class).createDeserializer();<br /><br />    List&lt;Dog&gt; dogs = new ArrayList&lt;Dog&gt;();<br /><br />    deserializer.open(new InputStreamReader(stream));<br />    while (deserializer.hasNext()) {<br />        dogs.add(deserializer.&lt;Dog&gt;next());<br />    }<br />    deserializer.close(true);<br /><br />    return dogs;<br />}</pre>Pour filtrer l'entête on est obligé d'ajouter un Filter, un simple boolean dans les config aurait été appréciable...<br/><br/><h2>Étape 2 : écriture de fichier CSV</h2>L'écriture n'est pas très compliquée non plus : <pre class="brush: java">public void writeFile(List&lt;Dog&gt; dogs, File file) throws IOException {<br />    CsvConfiguration config = new CsvConfiguration();<br />    config.setFieldDelimiter(',');<br />    Serializer serializer = CsvIOFactory.createFactory(config, Dog.class).createSerializer();<br /><br />    serializer.open(new FileWriter(file));<br />    for (Dog dog : dogs) {<br />        serializer.write(dog);<br />    }<br />    serializer.close(true);<br />}<br /></pre>Toujours pas moyen d'ajouter l'entête.<br/><br/> <h2>Étape 3 : validation</h2>Il existe une couche de validation, par contre elle n'est pas documentée, et je n'ai pas réussi à la faire fonctionner (n'hésitez pas à corriger mon code sur github si vous savez comment faire :) ).<br/><br/> <h2>Étape 4 : parsing complexe.</h2>Aucun problème avec les retour à la ligne pour JSefa.<br/><br/> <h2>Étape 5 : bench</h2>J'utilise les mêmes fichiers que pour BeanFiles.<br/>Pour le fichier moyen, le temps moyen de traitement est de 791ms.<br/><br/>Le gros fichier confirme le bench avec le fichier moyen : <ul><li>Temps de traitement moyen : 7 652ms</li></ul><br/><br/> <h1>open-csv</h1>C'est une librairie bas niveau (utilisée par la plupart des parseurs haut niveaux), je l'étudierai donc pas ici.<br/><br/> <h1>Ostermiller CSV</h1>Dans cette librairie, le mapping se fait à la main, je ne l'étudierai donc pas.<br/><br/> <h1>Skife CSV</h1>Encore une librairie bas niveau.<br/><br/> <h1>Super CSV</h1> Site : <a href="http://supercsv.sourceforge.net/">http://supercsv.sourceforge.net/</a><br/><br/> <h2>Étape 0 : Documentation et mise en place</h2>La mise en place n'est pas documentée, c'est pas du maven, dont pas si simple que ça, faut bien penser à mettre les deux jar dans les dépendances...<br/>De manière générale la documentation est plutôt pas mal (malgré le fait qu'il n'existe pas de documentation pour la mise en place).<br/><br/> <h2>Étape 1 : Lecture du fichier CSV simple</h2>Pas d'annotation pour cette librairie, tout se fait par le nom des attributs.<br/>Pour les options il faut passer par des CellProcessors, j'y reviendrai pour la validation.<br/><br/>La lecture n'est pas très compliquée : <pre class="brush: java"><br />public List&lt;Dog&gt; getDogs(InputStream stream) throws IOException {<br />    List&lt;Dog&gt; dogs = new ArrayList&lt;Dog&gt;();<br /><br />    ICsvBeanReader inFile = new CsvBeanReader(new InputStreamReader(stream), CsvPreference.STANDARD_PREFERENCE);<br />    final String[] header = inFile.getCSVHeader(true);<br />    Dog dog;<br />    while( (dog = inFile.read(Dog.class, header)) != null) {<br />        dogs.add(dog);<br />    }<br />    inFile.close();<br />    return dogs;<br />}</pre>La gestion de l'entête et l'itération se fait à la main, je trouve ça dommage. Pour le reste c'est plutôt efficace.<br/><br/><h2>Étape 2 : écriture de fichier CSV</h2>Pour l'écriture, il n'y a pas de gestion de mapping, tout ce fait à la main, du coup je ne l'étudierai pas ici.<br/><br/> <h2>Étape 3 : validation</h2>Pour la validation, c'est plutôt efficace, par contre cela repose sur l'ordre des champs, un peu dommage.<br/>Il faut donc déclarer un tableau de CellProcessor : <pre class="brush: java">public static final CellProcessor[] userProcessors = new CellProcessor[] {<br />        new NotNull(),<br />        new IsIncludedIn(new HashSet&lt;Object&gt;(DogValid.POSSIBLE_RACES)),<br />        null<br />};</pre>On passe ensuite ce tableau pour le parsing des lignes : <pre class="brush: java">inFile.read(DogValid.class, header, userProcessors)</pre><br/><br/><h2>Étape 4 : parsing complexe.</h2>Aucun problème avec les retours à la ligne pour Super Csv.<br/><br/> <h2>Étape 5 : bench</h2>J'utilise les mêmes fichiers que pour BeanFiles.<br/>Pour le fichier moyen, le temps moyen de traitement est de 749ms.<br/><br/>Le gros fichier confirme le bench avec le fichier moyen : <ul><li>Temps de traitement moyen : 7 523ms</li></ul><br/><br/> <h1>CsvEngine</h1> Pour ceux qui ne le savent pas, je suis le développeur de cette librairie, je ne suis donc sans doute pas très objectif :).<br/>Site : <a href="https://github.com/ybonnel/CsvEngine">https://github.com/ybonnel/CsvEngine</a><br/><br/> <h2>Étape 0 : Documentation et mise en place</h2>La mise en place est très simple et documentée : <a href="https://github.com/ybonnel/CsvEngine/wiki/Install">Wiki install</a>.<br/>De manière générale, entre le wiki, la javadoc et les tests, je pense objectivement que CsvEngine est la librairie la plus documentée de celles que j'ai testées.<br/><br/>   <h2>Étape 1 : Lecture du fichier CSV simple</h2>Il faut tout d'abord ajouter les annotations à la classe dog : <pre class="brush: java">@CsvDataType<br />@CsvFile<br />public class Dog {<br />    @CsvColumn("name")<br />    private String name;<br />    @CsvColumn("race")<br />    private String race;<br />    @CsvColumn("proprietary")<br />    private String proprietary;<br />}</pre>Un truc qu'il faudra ajouter dans CsvEngine et le fait de rendre le nom du champs CSV facultatif (déduit du nom de l'attribut).<br/><br/>La lecture est très simple : <pre class="brush: java"><br />public List&lt;Dog&gt; getDogs(InputStream stream) throws IOException, CsvErrorsExceededException {<br />    CsvEngine engine = new CsvEngine(Dog.class);<br />    return engine.parseInputStream(stream, Dog.class).getObjects();<br />}</pre><br/><br/> <h2>Étape 2 : écriture de fichier CSV</h2>L'écriture n'est pas plus compliquée que la lecture : <pre class="brush: java">public void writeFile(List&lt;Dog&gt; dogs, File file) throws IOException {<br />    CsvEngine engine = new CsvEngine(Dog.class);<br />    engine.writeFile(new FileWriter(file), dogs, Dog.class);<br />}</pre><br/><br/> <h2>Étape 3 : validation</h2>Pour la validation tout passe par les annotations : <pre class="brush: java">@CsvFile<br />public class DogValid {<br />    @CsvColumn(value = "name", mandatory = true)<br />    private String name;<br />    @CsvValidation(ValidatorRace.class)<br />    @CsvColumn(value = "race", mandatory = true)<br />    private String race;<br />    @CsvColumn("proprietary")<br />    private String proprietary;<br />    <br />    public static class ValidatorRace extends ValidatorCsv {<br />        @Override<br />        public void validate(String field) throws ValidateException {<br />            if (!POSSIBLE_RACES.contains(field)) {<br />                throw new ValidateException("The race \"" + field + "\" isn't correct");<br />            }<br />        }<br />    }<br />}<br /></pre> On lit ensuite la fichier comme d'habitude : <pre class="brush: java">public List&lt;DogValid&gt; readDogsValid(InputStream stream) throws CsvErrorsExceededException {<br />   CsvEngine engine = new CsvEngine(DogValid.class);<br />   return engine.parseInputStream(stream, DogValid.class).getObjects();<br />}</pre><br/><br/> <h2>Étape 4 : parsing complexe.</h2>Aucun problème avec les retour à la ligne pour CsvEngine.  <h2>Étape 5 : bench</h2>J'utilise les mêmes fichiers que pour BeanFiles. Pour le fichier moyen, le temps moyen de traitement est de 693ms.<br/><br/>Le gros fichier confirme le bench avec le fichier moyen : <ul><li>Temps de traitement moyen : 7 028ms</li></ul><br/><br/> <h1>Conclusion</h1> Première conclusion, écrire un article aussi long avec l'éditeur de Blogger est une corvée... faut que je trouve autre chose pour mon blog.<br/><br>Voici un petit tableau récapitulatif des tests que j'ai pu mené sur ces librairies :  <table border="1" style="text-align:center"><tr><th/><th>Documentation</th><th>Mise en place</th><th>Lecture</th><th>Écriture</th><th>Validation</th><th>Temps de traitement</th></tr><tr><td><a href="http://code.google.com/p/beanfiles">BeanFiles</a></td><td>-</td><td>-</td><td>=</td><td>X</td><td>X</td><td>15 120</td></tr><tr><td><a href="http://code.google.com/p/jcsv">JCsv</a></td><td>+</td><td>+</td><td>-</td><td>-</td><td>X</td><td>367 449</td></tr><tr><td><a href="http://jsefa.sourceforge.net">JSefa</a></td><td>-</td><td>=</td><td>-</td><td>=</td><td>-</td><td>7 652</td></tr><tr><td><a href="http://supercsv.sourceforge.net">Super CSV</a></td><td>+</td><td>=</td><td>+</td><td>-</td><td>+</td><td>7 523</td></tr><tr><td><a href="https://github.com/ybonnel/CsvEngine">CsvEngine</a></td><td>+</td><td>+</td><td>+</td><td>+</td><td>+</td><td>7 028</td></tr></table> Légende : <ul><li>X : N'existe pas</li><li>- : Existe mais pas terrible</li><li>= : Existe et marche plutôt bien</li><li>+ : Existe et est vraiment bien fait :)</li></ul> De mon point de vue tout à fait objectif CsvEngine est la meilleure librairie sur tout les points, son seul défaut est sans doute mon Anglais très approximatif.
